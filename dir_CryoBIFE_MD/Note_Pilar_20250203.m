run('/data/rangan/dir_cryoem/dir_rangan_playroom/setup_access1');
cd('/data/rangan/dir_cryoem/dir_CryoBIFE_MD');
dir_jpg = '/data/rangan/dir_cryoem/dir_CryoBIFE_MD';

flag_disp = 2; nf=0;
%%%%%%%%;
% Here we assume that LL_rc__(1+nr,1+nc) is the (affinely-transformed) log-likelihood: ;
% LL_rc__(1+nr,1+nc) = LL_a * log(P( A_{r} | F_{c} )) + LL_b ;
% for image A_{r} and model F_{c}. ;
% The affine-transformation is defined via the parameters LL_a and LL_b, ;
% which we assume are fixed for all images (nr) and models (nc). ;
% Below we will see that the results can depend sensitively on LL_a. ;
%%%%%%%%;
LL_rc__ = load('-ascii','../dir_CryoBIFE_MD/LogLikeMat_20250129.mat'); %<-- log-likelihoods.; 
[n_r,n_c] = size(LL_rc__);

%%%%%%%%;
% With this assumption we can see that the individual likelihoods are given by: ;
% P_rc__ := P( A_{r} | F_{c} ) = exp((LL_rc__(1+nr,1+nc)-LL_b)/LL_a). ;
%%%%;
% for now we will pick an arbitrary LL_b and LL_a for exposition. ;
%%%%%%%%;
LL_b = 1.15*max(LL_rc__,[],'all'); %<-- arbitrary. ;
LL_a = max(1e-12,1024*std(LL_rc__,1,'all')); %<-- arbitrary. ;
P_rc__ = exp((LL_rc__-LL_b)./max(1e-12,LL_a));
%%%%;
%figure(1+nf);nf=nf+1;clf;figsml;
%hist(P_rc__(:),linspace(0,1,1024));
%xlim([0,1]);xlabel('P');
%ylabel('#');
%title('histogram of probabilities');

%%%%%%%%;
% We will further assume that the models are distributed via rho_c_, ;
% such that the probability of sampling model nc is rho_c_(1+nc). ;
% Thus, the marginalized likelihoods for each image are given by: ;
% P( A_{r} | {F_{c}} ) := P( A_{r} ) = \sum_{c} P(A_{r}|F_{c}) \rho_{c}, ;
% or P_r_ := sum( P_rc__*rho_c_ , 2 ) . ;
% Similarly, the 'total' likelihood of observing all the images would be: ;
% P( {A_{r}} ) = \prod_{r} P(A_{r}), ;
% or P := prod( P_r_ , 'all') ;
%%%%;
% Now, if we were to try and maximize P with respect to rho_c_, ;
% we will inevitably have to deal with the constraints: 
% G(rho_c_) = sum(rho_c_) = 1. ;
% and rho_c_(1+nc)>=0 for each nc. ;
% These are inconvenient, so instead let us define: ;
% eta_c_ --> rho_c_(1+nc) = exp(eta_c_(1+nc))/Z, ;
% where Z = sum(exp(eta_c_)).;
% This representation is not perfect (as there can be underflow yielding Z\approx 0), ;
% but it should be a reasonable start. ;
% Note that:
% \partial_{\eta_{d}} Z = \exp(eta_{d}). ;
% \partial_{\eta_{d}} \rho_{c} = \exp(\eta_{c})/Z*\delta_{dc} - \exp(\eta_{c})\exp(\eta_{d})/Z^{2} ;
%%%%;
% With this representation we have: ;
% P(A_{r}) = \sum_{c} P(A_{r}|F_{c}) * \rho_{c} = \sum_{c} P(A_{r}|F_{c}) * exp(\eta_{c})/Z. ;
% and: ;
% \partial_{\eta_{d}} log(P(A_{r})) = \frac{ \sum_{c} P(A_{r}|F_{c}) * \partial_{\eta_{d}} \rho_{c} }{P(A_{r})}
% which could be tackled using gradient-descent. ;
%%%%%%%%;

%%%%%%%%;
% For now, let us not worry about gradient-descent, and instead try and visualize the problem.
% To start, let us limit ourselves to ony two models. ;
%%%%%%%%;
nc0 = 0; nc1 = 1; %<-- pick two models. ;
elim_ = [-5,+5];
n_eta = 1024;
eta0_e_ = transpose(linspace(min(elim_),max(elim_),n_eta));
d_eta0 = mean(diff(eta0_e_));
eta1 = 0;
Z_e_ = exp(eta0_e_) + exp(eta1);
rho0_e_ = exp(eta0_e_)./Z_e_;
rho1_e_ = exp(eta1)./Z_e_;
rho_ec__ = cat(2,rho0_e_,rho1_e_);
rho_ce__ = permute(rho_ec__,[2,1]);
%%%%%%%%;
% As a sanity check, imagine a scenario where the first 200 images are 9-times more likely to come from model 0, ;
% while the next 100 images are 9-times more likely to come from model 1. ;
%%%%%%%%;
tmp_P_rc__ = 0.1+[0.9*ones(200,1) , 0.0*ones(200,1) ; 0.0*ones(100,1) , 0.9*ones(100,1) ];
logP_e_ = reshape(sum( log( sum(bsxfun(@times,tmp_P_rc__(:,1+[nc0,nc1]),reshape(rho_ce__,[1,2,n_eta])),[2]) ) , [1] ),[n_eta,1]);
%%%%%%%%;
% As you can see, the optimal \log(P) occurs when \rho_{c} \approx \{ 2/3 , 1/3 \}. ;
%%%%%%%%;
[~,tmp_ij] = max(logP_e_);
rho0_opt = rho0_e_(tmp_ij);
rho1_opt = rho1_e_(tmp_ij);
disp(sprintf(' %% sanity-check: (rho0_opt,rho1_opt) = (%+0.3f,%+0.3f)',rho0_opt,rho1_opt));
%%%%%%%%;
% Instead of simply considering the maximum-likelihood point, ;
% we can try and calculate the average rho_c_. ;
%%%%%%%%;
len0_e_ = 0.5*[rho0_e_(2:end);rho0_e_(end)] - 0.5*[rho0_e_(1);rho0_e_(1:end-1)] ;
len0_e_ = len0_e_*sqrt(2)/max(1e-12,sum(len0_e_));
logP_max = max(logP_e_,[],'all');
logP_sub_max_e_ = logP_e_ - logP_max;
P_div_max_e_ = exp(logP_sub_max_e_);
P_div_max_nrm_e_ = P_div_max_e_./max(1e-12,sum(P_div_max_e_.*len0_e_)); %<-- now sum(P_div_max_nrm_e_.*len0_e_)==1. ;
rho0_avg = sum( rho0_e_.*P_div_max_nrm_e_.*len0_e_ );
eta0_avg = interp1(rho0_e_,eta0_e_,rho0_avg);
rho1_avg = 1-rho0_avg;
disp(sprintf(' %% sanity-check: (rho0_avg,rho1_avg) = (%+0.3f,%+0.3f)',rho0_avg,rho1_avg));
%%%%%%%%;
% Note above that we normalized P_div_max_e_ so that it integrated to one over the simplex. ;
% This means that the resulting rho0_avg is insensitive to any prefactor in P_div_max_e_, ;
% which implies that rho0_avg is insensitive to any prefactor in P_rc__. ;
% More simply, the results will not change w.r.t. LL_b. ;
%%%%%%%%;
% In this case the average is close to the optimal. ;
%%%%%%%%;
if flag_disp>1;
figure(1+nf);nf=nf+1;clf;figsml;
fontsize_use = 12;
hold on;
plot(eta0_e_,logP_e_,'k.-');
[~,tmp_ij] = max(logP_e_,[],'all');
plot(eta0_e_(tmp_ij),logP_e_(tmp_ij),'r+','LineWidth',2,'MarkerFaceColor','c','MarkerSize',24);
plot(eta0_avg*[1,1],[min(logP_e_),max(logP_e_)],'c-','LineWidth',2);
hold off;
legend({'logP','opt','avg'},'Location','SouthEast');
xlim(elim_); xlabel('$\eta_{0}$','Interpreter','latex');
ylabel('$\log(P)$','Interpreter','latex');
set(gca,'FontSize',fontsize_use);
fname_fig_pre = sprintf('%s/Note_Pilar_20250203_FIGA',dir_jpg);
fname_fig_jpg = sprintf('%s.jpg',fname_fig_pre);
disp(sprintf(' %% writing %s',fname_fig_pre));
print('-djpeg',fname_fig_jpg);
end;%if flag_disp>1;
%%%%%%%%;
% Now rerun the same code using two of the models from the data-set. ;
%%%%%%%%;
nc0 = 2; nc1 = 3; %<-- pick two models. ;
logP_e_ = reshape(sum( log( sum(bsxfun(@times,P_rc__(:,1+[nc0,nc1]),reshape(rho_ce__,[1,2,n_eta])),[2]) ) , [1] ),[n_eta,1]);
%%%%%%%%;
[~,tmp_ij] = max(logP_e_);
rho0_opt = rho0_e_(tmp_ij);
rho1_opt = rho1_e_(tmp_ij);
disp(sprintf(' %% first-two-models in real-data: (rho0_opt,rho1_opt) = (%+0.3f,%+0.3f)',rho0_opt,rho1_opt));
%%%%%%%%;
len0_e_ = 0.5*[rho0_e_(2:end);rho0_e_(end)] - 0.5*[rho0_e_(1);rho0_e_(1:end-1)] ;
len0_e_ = len0_e_*sqrt(2)/max(1e-12,sum(len0_e_));
logP_max = max(logP_e_,[],'all');
logP_sub_max_e_ = logP_e_ - logP_max;
P_div_max_e_ = exp(logP_sub_max_e_);
P_div_max_nrm_e_ = P_div_max_e_./max(1e-12,sum(P_div_max_e_.*len0_e_)); %<-- now sum(P_div_max_nrm_e_.*len0_e_)==1. ;
rho0_avg = sum( rho0_e_.*P_div_max_nrm_e_.*len0_e_ );
eta0_avg = interp1(rho0_e_,eta0_e_,rho0_avg);
rho1_avg = 1-rho0_avg;
disp(sprintf(' %% first-two-models in real-data: (rho0_avg,rho1_avg) = (%+0.3f,%+0.3f)',rho0_avg,rho1_avg));
%%%%%%%%;
if flag_disp>1;
figure(1+nf);nf=nf+1;clf;figmed;
fontsize_use = 12;
subplot(1,2,1);
hold on;
plot(eta0_e_,logP_e_,'k.-');
[~,tmp_ij] = max(logP_e_,[],'all');
plot(eta0_e_(tmp_ij),logP_e_(tmp_ij),'r+','LineWidth',2,'MarkerFaceColor','c','MarkerSize',24);
plot(eta0_avg*[1,1],[min(logP_e_),max(logP_e_)],'c-','LineWidth',2);
hold off;
legend({'logP','opt','avg'},'Location','SouthEast');
xlim(elim_); xlabel('$\eta_{0}$','Interpreter','latex');
ylabel('$\log(P)$','Interpreter','latex');
set(gca,'FontSize',fontsize_use);
subplot(1,2,2);
hold on;
plot(rho0_e_,P_div_max_nrm_e_,'k.-');
[~,tmp_ij] = max(P_div_max_nrm_e_,[],'all');
plot(rho0_e_(tmp_ij),P_div_max_nrm_e_(tmp_ij),'r+','LineWidth',2,'MarkerFaceColor','c','MarkerSize',24);
plot(rho0_avg*[1,1],[min(P_div_max_nrm_e_),max(P_div_max_nrm_e_)],'c-','LineWidth',2);
hold off;
legend({'P','opt','avg'},'Location','SouthEast');
xlim([0,1]); xlabel('$\rho_{0}$','Interpreter','latex');
ylim([0,1]);ylabel('$P$ (rescaled)','Interpreter','latex');
set(gca,'FontSize',fontsize_use);
fname_fig_pre = sprintf('%s/Note_Pilar_20250203_FIGB',dir_jpg);
fname_fig_jpg = sprintf('%s.jpg',fname_fig_pre);
disp(sprintf(' %% writing %s',fname_fig_pre));
print('-djpeg',fname_fig_jpg);
end;%if flag_disp>1;
%%%%%%%%;

%%%%%%%%;
% Now we could also work on three models. ;
%%%%%%%%;
nc0 = 0; nc1 = 1; nc2 = 2; %<-- pick three models. ;
elim_ = [-5,+5];
n_eta = 128;
eta0_e_ = transpose(linspace(min(elim_),max(elim_),n_eta));
eta1_e_ = transpose(linspace(min(elim_),max(elim_),n_eta));
eta2 = 0;
[eta0_ee__,eta1_ee__] = ndgrid(eta0_e_,eta1_e_);
Z_ee__ = exp(eta0_ee__) + exp(eta1_ee__) + exp(eta2);
rho0_ee__ = exp(eta0_ee__)./Z_ee__;
rho1_ee__ = exp(eta1_ee__)./Z_ee__;
rho2_ee__ = exp(eta2     )./Z_ee__;
rho_eec___ = cat(3,rho0_ee__,rho1_ee__,rho2_ee__);
rho_cee___ = permute(rho_eec___,[3,1,2]);
%%%%%%%%;
% As a sanity check, imagine a scenario where the first 300 images are most likely to come from model 0, ;
% while the next 200 images are most likely to come from model 1, ;
% and the next 100 images are most likely to come from model 2, ;
%%%%%%%%;
tmp_P_rc__ = [ ...
  0.8*ones(300,1) , 0.1*ones(300,1) , 0.1*ones(300,1) ...
; 0.1*ones(200,1) , 0.8*ones(200,1) , 0.1*ones(200,1) ...
; 0.1*ones(100,1) , 0.1*ones(100,1) , 0.8*ones(100,1) ...
];
logP_ee__ = reshape(sum( log( sum(bsxfun(@times,tmp_P_rc__(:,1+[nc0,nc1,nc2]),reshape(rho_cee___,[1,3,n_eta,n_eta])),[2]) ) , [1] ),[n_eta,n_eta]);
%%%%%%%%;
% As you can see, the optimal \log(P) occurs when \rho_{c} \approx \{ 3/6 , 2/6 , 1/6 \}. ;
%%%%%%%%;
[~,ij_opt] = max(logP_ee__,[],'all');
index_opt = ij_opt - 1;
ne0_opt = mod(index_opt,n_eta); index_opt = index_opt-ne0_opt; index_opt = index_opt/n_eta;
ne1_opt = mod(index_opt,n_eta); index_opt = index_opt-ne1_opt; index_opt = index_opt/n_eta;
assert(index_opt==0);
rho0_opt = rho0_ee__(ij_opt);
rho1_opt = rho1_ee__(ij_opt);
rho2_opt = rho2_ee__(ij_opt);
disp(sprintf(' %% sanity-check: (rho0_opt,rho1_opt,rho2_opt) = (%+0.3f,%+0.3f,%+0.3f)',rho0_opt,rho1_opt,rho2_opt));
%%%%%%%%;
% Instead of simply considering the maximum-likelihood point, ;
% we can try and calculate the average rho_c_. ;
%%%%%%%%;
[ ...
 ~ ...
,T_23__ ...
,heron_ee_ ...
] = ...
patch_simplex_3_0( ...
 struct('flag_plot',0) ...
,rho0_ee__ ...
,rho1_ee__ ...
);
heron_ee_ = heron_ee_*sqrt(3)/2/max(1e-12,sum(heron_ee_)); %<-- volume of n_simplex = s^n/n!, take partial+scale --> area of n_simplex = sqrt(n)/(n-1)! ;
heron_ee__ = reshape(heron_ee_,[n_eta,n_eta]);
logP_max = max(logP_ee__,[],'all');
logP_sub_max_ee__ = logP_ee__ - logP_max;
P_div_max_ee__ = exp(logP_sub_max_ee__);
P_div_max_nrm_ee__ = P_div_max_ee__./max(1e-12,sum(P_div_max_ee__.*heron_ee__,'all')); %<-- now sum(P_div_max_nrm_ee__.*heron_ee__,'all')==1. ;
rho0_avg = sum( rho0_ee__.*P_div_max_nrm_ee__.*heron_ee__ , 'all' );
rho1_avg = sum( rho1_ee__.*P_div_max_nrm_ee__.*heron_ee__ , 'all' );
rho2_avg = 1 - rho0_avg - rho1_avg ;
disp(sprintf(' %% sanity-check: (rho0_avg,rho1_avg,rho2_avg) = (%+0.3f,%+0.3f,%+0.3f)',rho0_avg,rho1_avg,rho2_avg));
%%%%;
if flag_disp>1;
figure(1+nf);nf=nf+1;clf;figbig;figbeach;
fontsize_use = 12;
markersize_use = 8;
p_row = 2; p_col = 2; np=0;
%%%%;
for nplot=0:2-1;
%%%%;
if nplot==0; tmp_ee__ = logP_ee__; tmp_str = 'logP_ee__'; end;
if nplot==1; tmp_ee__ = P_div_max_nrm_ee__; tmp_str = 'P_div_max_nrm_ee__'; end;
%%%%;
subplot(p_row,p_col,1+np);np=np+1;cla;
hold on;
imagesc(tmp_ee__);
plot(ne1_opt,ne0_opt,'wo','MarkerSize',markersize_use,'MarkerFaceColor',0.65*[1,1,1]);
hold off;
axisnotick();
axis image;
ylabel('$\eta_{0}$','Interpreter','latex');
xlabel('$\eta_{1}$','Interpreter','latex');
title(sprintf('%s on atlas',tmp_str),'Interpreter','none');
set(gca,'FontSize',fontsize_use);
%%%%;
subplot(p_row,p_col,1+np);np=np+1;cla;
hold on;
patch_simplex_3_0( ...
 struct('flag_plot',1) ...
,rho0_ee__ ...
,rho1_ee__ ...
,tmp_ee__ ...
);
tmp_opt_ = T_23__*[rho0_opt;rho1_opt;rho2_opt];
plot(tmp_opt_(1+0),tmp_opt_(1+1),'wo','MarkerSize',markersize_use,'MarkerFaceColor',0.65*[1,1,1]);
tmp_avg_ = T_23__*[rho0_avg;rho1_avg;rho2_avg];
plot(tmp_avg_(1+0),tmp_avg_(1+1),'ko','MarkerSize',markersize_use,'MarkerFaceColor',0.95*[1,1,1]);
hold off;
axis image;
axisnotick();
ylabel('$\rho_{2}$ vs $\{\rho_{0},\rho_{1}\}$','Interpreter','latex');
xlabel('$\rho_{0}$ vs $\rho_{1}$','Interpreter','latex');
title(sprintf('%s on simplex',tmp_str),'Interpreter','none');
set(gca,'FontSize',fontsize_use);
%%%%;
end;%for nplot=0:2-1;
fname_fig_pre = sprintf('%s/Note_Pilar_20250203_FIGC',dir_jpg);
fname_fig_jpg = sprintf('%s.jpg',fname_fig_pre);
disp(sprintf(' %% writing %s',fname_fig_pre));
print('-djpeg',fname_fig_jpg);
end;%if flag_disp>1;
%%%%%%%%;

LL_b = 1.15*max(LL_rc__,[],'all'); %<-- arbitrary. ;
LL_a = max(1e-12,16*std(LL_rc__,1,'all')); %<-- arbitrary. ;
P_rc__ = exp((LL_rc__-LL_b)./max(1e-12,LL_a));
%%%%%%%%;
% Now run the same code using three of the models from the data-set. ;
%%%%%%%%;
nc0 = 0; nc1 = 1; nc2 = 2; %<-- pick three models. ;
logP_ee__ = reshape(sum( log( sum(bsxfun(@times,P_rc__(:,1+[nc0,nc1,nc2]),reshape(rho_cee___,[1,3,n_eta,n_eta])),[2]) ) , [1] ),[n_eta,n_eta]);
%%%%%%%%;
% Now optimize: ;
%%%%%%%%;
[~,ij_opt] = max(logP_ee__,[],'all');
index_opt = ij_opt - 1;
ne0_opt = mod(index_opt,n_eta); index_opt = index_opt-ne0_opt; index_opt = index_opt/n_eta;
ne1_opt = mod(index_opt,n_eta); index_opt = index_opt-ne1_opt; index_opt = index_opt/n_eta;
assert(index_opt==0);
n_3 = 3;
%nlP3 = @(eta_c_) -sum( log( P_rc__(:,1+[nc0,nc1,nc2])* exp(eta_c_)/max(1e-300,sum(exp(eta_c_))) ) , 1 );
nlP3 = @(eta_ct__) -sum( log( bsxfun( @rdivide , P_rc__(:,1+[nc0,nc1,nc2])* exp(eta_ct__) , max(1e-300,sum(exp(eta_ct__),1)) ) ) , 1 );
tmp_option = optimset('Display','iter','MaxFunEvals',1024,'MaxIter',1024,'TolFun',1e1);
[eta_opt_c_,nlP_opt] = fminsearch(nlP3,zeros(n_3,1),tmp_option);
rho_opt_c_ = exp(eta_opt_c_)/max(1e-300,sum(exp(eta_opt_c_)));
disp(sprintf(' %% (nc0,nc1,nc2)=(%.2d,%.2d,%.2d) --> rho_opt_c_=(+%0.3f,+%0.3f,+%0.3f)',nc0,nc1,nc2,rho_opt_c_));
rho0_opt = rho_opt_c_(1+0);
rho1_opt = rho_opt_c_(1+1);
rho2_opt = rho_opt_c_(1+2);
disp(sprintf(' %% (nc0,nc1,nc2)=(%.2d,%.2d,%.2d) --> rho_opt_c_=(%+0.3f,%+0.3f,%+0.3f)',nc0,nc1,nc2,rho0_opt,rho1_opt,rho2_opt));
%%%%%%%%;
% Now find average. ;
% Again, this involves normalizing over the simplex, ;
% so LL_b will be ignored. ;
%%%%%%%%;
logP_max = max(logP_ee__,[],'all');
logP_sub_max_ee__ = logP_ee__ - logP_max;
P_div_max_ee__ = exp(logP_sub_max_ee__);
P_div_max_nrm_ee__ = P_div_max_ee__./max(1e-12,sum(P_div_max_ee__.*heron_ee__,'all')); %<-- now sum(P_div_max_nrm_ee__.*heron_ee__,'all')==1. ;
rho0_avg = sum( rho0_ee__.*P_div_max_nrm_ee__.*heron_ee__ , 'all' );
rho1_avg = sum( rho1_ee__.*P_div_max_nrm_ee__.*heron_ee__ , 'all' );
rho2_avg = 1 - rho0_avg - rho1_avg ;
disp(sprintf(' %% (nc0,nc1,nc2)=(%.2d,%.2d,%.2d) --> rho_avg_c_=(%+0.3f,%+0.3f,%+0.3f)',nc0,nc1,nc2,rho0_avg,rho1_avg,rho2_avg));
%%%%;
if flag_disp>1;
figure(1+nf);nf=nf+1;clf;figbig;figbeach;
fontsize_use = 12;
markersize_use = 8;
p_row = 2; p_col = 2; np=0;
%%%%;
for nplot=0:2-1;
%%%%;
if nplot==0; tmp_ee__ = logP_ee__; tmp_str = 'logP_ee__'; end;
if nplot==1; tmp_ee__ = P_div_max_nrm_ee__; tmp_str = 'P_div_max_nrm_ee__'; end;
%%%%;
subplot(p_row,p_col,1+np);np=np+1;cla;
hold on;
imagesc(tmp_ee__);
plot(ne1_opt,ne0_opt,'wo','MarkerSize',markersize_use,'MarkerFaceColor',0.65*[1,1,1]);
hold off;
axisnotick();
axis image;
ylabel('$\eta_{0}$','Interpreter','latex');
xlabel('$\eta_{1}$','Interpreter','latex');
title(sprintf('%s on atlas',tmp_str),'Interpreter','none');
set(gca,'FontSize',fontsize_use);
%%%%;
subplot(p_row,p_col,1+np);np=np+1;cla;
hold on;
patch_simplex_3_0( ...
 struct('flag_plot',1) ...
,rho0_ee__ ...
,rho1_ee__ ...
,tmp_ee__ ...
);
tmp_opt_ = T_23__*[rho0_opt;rho1_opt;rho2_opt];
plot(tmp_opt_(1+0),tmp_opt_(1+1),'wo','MarkerSize',markersize_use,'MarkerFaceColor',0.65*[1,1,1]);
tmp_avg_ = T_23__*[rho0_avg;rho1_avg;rho2_avg];
plot(tmp_avg_(1+0),tmp_avg_(1+1),'ko','MarkerSize',markersize_use,'MarkerFaceColor',0.95*[1,1,1]);
hold off;
axis image;
axisnotick();
ylabel('$\rho_{2}$ vs $\{\rho_{0},\rho_{1}\}$','Interpreter','latex');
xlabel('$\rho_{0}$ vs $\rho_{1}$','Interpreter','latex');
title(sprintf('%s on simplex',tmp_str),'Interpreter','none');
set(gca,'FontSize',fontsize_use);
%%%%;
end;%for nplot=0:2-1;
fname_fig_pre = sprintf('%s/Note_Pilar_20250203_FIGD',dir_jpg);
fname_fig_jpg = sprintf('%s.jpg',fname_fig_pre);
disp(sprintf(' %% writing %s',fname_fig_pre));
print('-djpeg',fname_fig_jpg);
end;%if flag_disp>1;
%%%%%%%%;

%%%%%%%%;
% Now, as you can see, the location of the mean depends on the scaling of the log-likelihood. ;
% We repeat the calculation for a variety of affine-transformations. ;
%%%%%%%%;
nc0 = 0; nc1 = 1; nc2 = 2; %<-- pick three models. ;
n_LL_b = 1; LL_b_ = transpose(linspace(1.00,1.15,n_LL_b))*max(LL_rc__,[],'all'); %<-- no variation w.r.t LL_b, so just pick one. ;
n_LL_a = 8; LL_a_ = transpose(2.^[1:8])*max(1e-12,std(LL_rc__,1,'all')); %<-- noticeable variation w.r.t LL_a. ;
%%%%%%%%;
if flag_disp>0;
figure(1+nf);nf=nf+1;clf;figbig;
fontsize_use = 12; markersize_use = 8;
p_row = 2; p_col = ceil(n_LL_a/max(1,p_row)); np=0;
%%%%;
nLL_b = 0;
for nLL_a=0:n_LL_a-1;
LL_a = LL_a_(1+nLL_a);
LL_b = LL_b_(1+nLL_b);
P_rc__ = exp((LL_rc__-LL_b)./max(1e-12,LL_a));
logP_ee__ = reshape(sum( log( sum(bsxfun(@times,P_rc__(:,1+[nc0,nc1,nc2]),reshape(rho_cee___,[1,3,n_eta,n_eta])),[2]) ) , [1] ),[n_eta,n_eta]);
%%%%;
[~,ij_opt] = max(logP_ee__,[],'all');
index_opt = ij_opt - 1;
ne0_opt = mod(index_opt,n_eta); index_opt = index_opt-ne0_opt; index_opt = index_opt/n_eta;
ne1_opt = mod(index_opt,n_eta); index_opt = index_opt-ne1_opt; index_opt = index_opt/n_eta;
assert(index_opt==0);
n_3 = 3;
nlP3 = @(eta_ct__) -sum( log( bsxfun( @rdivide , P_rc__(:,1+[nc0,nc1,nc2])* exp(eta_ct__) , max(1e-300,sum(exp(eta_ct__),1)) ) ) , 1 );
tmp_option = optimset('Display','none','MaxFunEvals',1024,'MaxIter',1024,'TolFun',1e1);
[eta_opt_c_,nlP_opt] = fminsearch(nlP3,zeros(n_3,1),tmp_option);
rho_opt_c_ = exp(eta_opt_c_)/max(1e-300,sum(exp(eta_opt_c_)));
rho0_opt = rho_opt_c_(1+0); rho1_opt = rho_opt_c_(1+1); rho2_opt = rho_opt_c_(1+2);
%%%%;
logP_max = max(logP_ee__,[],'all');
logP_sub_max_ee__ = logP_ee__ - logP_max;
P_div_max_ee__ = exp(logP_sub_max_ee__);
P_div_max_nrm_ee__ = P_div_max_ee__./max(1e-12,sum(P_div_max_ee__.*heron_ee__,'all')); %<-- now sum(P_div_max_nrm_ee__.*heron_ee__,'all')==1. ;
rho0_avg = sum( rho0_ee__.*P_div_max_nrm_ee__.*heron_ee__ , 'all' );
rho1_avg = sum( rho1_ee__.*P_div_max_nrm_ee__.*heron_ee__ , 'all' );
rho2_avg = 1 - rho0_avg - rho1_avg ;
%%%%;
tmp_ee__ = P_div_max_nrm_ee__; tmp_str = 'P_div_max_nrm_ee__';
subplot(p_row,p_col,1+np);np=np+1;cla;
hold on;
patch_simplex_3_0( ...
 struct('flag_plot',1) ...
,rho0_ee__ ...
,rho1_ee__ ...
,tmp_ee__ ...
);
tmp_opt_ = T_23__*[rho0_opt;rho1_opt;rho2_opt];
plot(tmp_opt_(1+0),tmp_opt_(1+1),'wo','MarkerSize',markersize_use,'MarkerFaceColor',0.65*[1,1,1]);
tmp_avg_ = T_23__*[rho0_avg;rho1_avg;rho2_avg];
plot(tmp_avg_(1+0),tmp_avg_(1+1),'ko','MarkerSize',markersize_use,'MarkerFaceColor',0.95*[1,1,1]);
hold off;
axis image;
axisnotick();
ylabel('$\rho_{2}$ vs $\{\rho_{0},\rho_{1}\}$','Interpreter','latex');
xlabel('$\rho_{0}$ vs $\rho_{1}$','Interpreter','latex');
%title(sprintf('nLL_a %d nLL_b %d',nLL_a,nLL_b),'Interpreter','none');
title(sprintf('nLL_a %d',nLL_a),'Interpreter','none');
set(gca,'FontSize',fontsize_use);
drawnow();
%%%%;
end;%for nLL_a=0:n_LL_a-1;
sgtitle(sprintf('nc0 %d nc1 %d nc2 %d',nc0,nc1,nc2));
%%%%;
fname_fig_pre = sprintf('%s/Note_Pilar_20250203_FIGE',dir_jpg);
fname_fig_jpg = sprintf('%s.jpg',fname_fig_pre);
disp(sprintf(' %% writing %s',fname_fig_pre));
print('-djpeg',fname_fig_jpg);
end;%if flag_disp>0;
%%%%%%%%;

disp(sprintf(' %% returning before considering higher dimensional problem. ')); return;

%%%%%%%%;
% Now we can apply the same idea across the entire data-set. ;
%%%%%%%%;
LL_b = 1.15*max(LL_rc__,[],'all'); %<-- arbitrary. ;
LL_a = max(1e-12,1024*std(LL_rc__,1,'all')); %<-- arbitrary. ;
P_rc__ = exp((LL_rc__-LL_b)./max(1e-12,LL_a));
P_rc__ = bsxfun(@rdivide,P_rc__,sum(P_rc__,1));
P_rc__ = bsxfun(@rdivide,P_rc__,sum(P_rc__,2));
P_rc__ = bsxfun(@rdivide,P_rc__,sum(P_rc__,1));
P_rc__ = bsxfun(@rdivide,P_rc__,sum(P_rc__,2));
%%%%%%%%;
tmp_option = optimset('Display','off','MaxFunEvals',1024,'MaxIter',1024,'TolFun',1e1);
nlPX = @(eta_ct__) -sum( log( bsxfun( @rdivide , P_rc__* exp(eta_ct__) , max(1e-300,sum(exp(eta_ct__),1)) ) ) , 1 );
n_t = 1024*32;
rng(0);
eta_rand_ct__ = max(elim_)*randn(n_c,n_t);
nlP_t_ = nlPX(eta_rand_ct__);
[~,tmp_ij_] = sort(nlP_t_,'ascend');
n_s = min(n_t,128);
nlP_opt = +Inf; eta_opt_c_ = zeros(n_c,1);
for ns=0;n_s-1;
tmp_ij = tmp_ij_(1+ns);
eta_init_c_ = eta_rand_ct__(:,tmp_ij);
[eta_sub_c_,nlP_sub] = fminsearch(nlPX,eta_init_c_,tmp_option);
if (nlP_sub< nlP_opt);
nlP_opt = nlP_sub;
eta_opt_c_ = eta_sub_c_;
end;%if (nlP_sub< nlP_opt);
end;%for ns=0;n_s-1;
rho_opt_c_ = exp(eta_opt_c_)/max(1e-300,sum(exp(eta_opt_c_)));
%%%%;
figure(1+nf);nf=nf+1;clf;figmed;
markersize_use = 16;
subplot(1,2,1);
plot(1:n_c,eta_opt_c_,'g.','MarkerSize',markersize_use);
xlim([0,1+n_c]); xlabel('model-ij 1+nc');
ylabel('eta');
subplot(1,2,2);
plot(1:n_c,rho_opt_c_,'r.','MarkerSize',markersize_use);
xlim([0,1+n_c]); xlabel('model-ij 1+nc');
ylabel('rho');
%%%%%%%%;
% As you can see, the high overall likelihood of model nc==4 dominates the calculation. ;
% This, coupled with the fact that the model nc==4 is not relatively unlikely for many images, ;
% produces a maximum-likelihood estimate for rho_c_ that is dominated by rho_c_(1+4). ;
%%%%%%%%;
figure(1+nf);nf=nf+1;clf;figsml;
hold on;
plot(1:n_c,mean(P_rc__,1),'o');
plot(1+4,mean(P_rc__(:,1+4),1),'rx');
hold off;
xlim([0,n_c+1]); xlabel('model-ij 1+nc');
grid on;
%%%%%%%%;


