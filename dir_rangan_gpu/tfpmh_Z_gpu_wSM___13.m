function ...
[ ...
 parameter ...
,Z_gpu_wSM___ ... %<-- or Z_gpu_SM__. ;
,UX_CTF_R_S_l2_gpu_wSM___ ... %<-- or UX_CTF_R_S_l2_gpu_SM__. ;
,UX_T_M_l2_gpu_dM__ ...
,UX_M_l2_gpu_M_ ...
,X_gpu_wSM___ ... %<-- or X_gpu_SM__. ;
,delta_x_gpu_wSM___ ... %<-- or delta_x_gpu_SM__. ;
,delta_y_gpu_wSM___ ... %<-- or delta_y_gpu_SM__. ;
,gamma_z_gpu_wSM___ ... %<-- or gamma_z_gpu_SM__. ;
,index_sub_gpu_wSM___ ... %<-- or index_sub_gpu_SM__. ;
,Z_dwSM____ ...
,X_dwSM____ ...
] = ...
tfpmh_Z_gpu_wSM___13( ...
 parameter ...
,n_k_p_r ...
,k_p_r_ ...
,k_p_r_max ...
,n_w_ ...
,weight_2d_k_p_r_ ...
,weight_2d_k_p_wk_ ...
,n_M ...
,M_k_p_wkM__ ...
,CTF_k_p_wkM__ ...
,n_S ...
,S_k_p_wkS__ ...
,pm_n_UX_rank ...
,pm_UX_kn__ ...
,pm_X_weight_r_ ...
,FTK ...
);
%%%%%%%%;
% based on tfpmh_Z_wSM___13.m. ;
% Assumes n_w_ = n_w_max*ones(n_k_p_r,1);
%%%%%%%%;

str_thisfunction = 'tfpmh_Z_gpu_wSM___13';

na=0;
if (nargin<1+na); parameter=[]; end; na=na+1;
if (nargin<1+na); n_k_p_r=[]; end; na=na+1;
if (nargin<1+na); k_p_r_=[]; end; na=na+1;
if (nargin<1+na); k_p_r_max=[]; end; na=na+1;
if (nargin<1+na); n_w_=[]; end; na=na+1;
if (nargin<1+na); weight_2d_k_p_r_=[]; end; na=na+1;
if (nargin<1+na); weight_2d_k_p_wk_=[]; end; na=na+1;
if (nargin<1+na); n_M=[]; end; na=na+1;
if (nargin<1+na); M_k_p_wkM__=[]; end; na=na+1;
if (nargin<1+na); CTF_k_p_wkM__=[]; end; na=na+1;
if (nargin<1+na); n_S=[]; end; na=na+1;
if (nargin<1+na); S_k_p_wkS__=[]; end; na=na+1;
if (nargin<1+na); pm_n_UX_rank=[]; end; na=na+1;
if (nargin<1+na); pm_UX_kn__=[]; end; na=na+1;
if (nargin<1+na); pm_X_weight_r_=[]; end; na=na+1;
if (nargin<1+na); FTK=[]; end; na=na+1;

if isempty(parameter); parameter = struct('type','parameter'); end;%if isempty(parameter);
%%%%%%%%;
if (~isfield(parameter,'flag_verbose')); parameter.flag_verbose = 0; end; %<-- parameter_bookmark. ;
flag_verbose = parameter.flag_verbose;
if (~isfield(parameter,'tolerance_master')); parameter.tolerance_master = 1e-2; end; %<-- parameter_bookmark. ;
tolerance_master = parameter.tolerance_master;
if (~isfield(parameter,'n_M_per_Mbatch')); parameter.n_M_per_Mbatch = 24; end; %<-- parameter_bookmark. ;
n_M_per_Mbatch = parameter.n_M_per_Mbatch;
if (~isfield(parameter,'n_S_per_Sbatch')); parameter.n_S_per_Sbatch = 24; end; %<-- parameter_bookmark. ;
n_S_per_Sbatch = parameter.n_S_per_Sbatch;
if (~isfield(parameter,'flag_optimize_over_gamma_z')); parameter.flag_optimize_over_gamma_z = 0; end; %<-- parameter_bookmark. ;
flag_optimize_over_gamma_z = parameter.flag_optimize_over_gamma_z;
if (~isfield(parameter,'flag_dwSM')); parameter.flag_dwSM = 0; end; %<-- parameter_bookmark. ;
flag_dwSM = parameter.flag_dwSM;
if (~isfield(parameter,'flag_CTF_anisotropic')); parameter.flag_CTF_anisotropic = 1; end; %<-- parameter_bookmark. ;
flag_CTF_anisotropic = parameter.flag_CTF_anisotropic;
if (~isfield(parameter,'memory_limit_GB')); parameter.memory_limit_GB = 4.0; end; %<-- parameter_bookmark. ;
memory_limit_GB = parameter.memory_limit_GB;
%%%%%%%%;

nf=0;
if (flag_verbose>0); disp(sprintf(' %% [entering %s]',str_thisfunction)); end;

n_byte_per_float32 = 4; n_byte_per_float64 = 8;
n_byte_per_complex64 = 8; n_byte_per_complex128 = 16;

f_zero = gpuArray( single(0.0) );
%%%%;
tmp_t = tic();
delta_gpu_x_ = gpuArray( (FTK.delta_x_) ); delta_gpu_y_ = gpuArray( (FTK.delta_y_) );
svd_U_d_expiw_s_gpu__ = gpuArray( (FTK.svd_U_d_expiw_s__) );
tmp_t = toc(tmp_t); if (flag_verbose>0); disp(sprintf(' %% svd_U_d_expiw_s_gpu__ %0.6fs',tmp_t)); end;%if (flag_verbose>0);
%%%%;

n_w_ = n_w_(:);
n_w_max = max(n_w_);
n_w_sum = sum(n_w_);
n_w_csum_ = cumsum([0;n_w_]);
if (n_w_sum~=n_w_max*n_k_p_r); disp(sprintf(' %% Warning, n_w_sum %d ~= n_w_max*n_k_p_r %d*%d in %s',n_w_sum,n_w_max,n_k_p_r,str_thisfunction)); end;
n_delta_v = FTK.n_delta_v;
n_svd_l = FTK.n_svd_l;
tmp_index_d0 = intersect(efind(FTK.delta_x_==0),efind(FTK.delta_y_==0)); assert(numel(tmp_index_d0)==1); %<-- should be a single index corresponding to zero-displacement. ;
pm_n_k_p_r = pm_n_UX_rank; pm_n_w_max = n_w_max;
pm_n_w_ = pm_n_w_max*ones(pm_n_k_p_r,1);
pm_n_w_sum = pm_n_k_p_r*pm_n_w_max;
pm_wUX_kn__ = diag(pm_X_weight_r_)*pm_UX_kn__;
pm_X_weight_gpu_r_ = gpuArray( (pm_X_weight_r_) );
pm_UX_gpu_kn__ = gpuArray( (pm_UX_kn__) );
%pm_wUX_gpu_kn__ = gpuArray( (pm_wUX_kn__) );

%%%%%%%%;
% allocate memory for output. ;
%%%%%%%%;
UX_T_M_l2_gpu_dM__ = zeros(n_delta_v,n_M,'like',f_zero);
UX_M_l2_gpu_M_ = zeros(n_M,1,'like',f_zero);
if flag_optimize_over_gamma_z==0;
Z_gpu_wSM___ = zeros(n_w_max,n_S,n_M,'like',f_zero);
if flag_CTF_anisotropic==1; UX_CTF_R_S_l2_gpu_wSM___ = zeros(n_w_max,n_S,n_M,'like',f_zero); end;
if flag_CTF_anisotropic==0; UX_CTF_R_S_l2_gpu_wSM___ = zeros(n_S,n_M,'like',f_zero); end;
X_gpu_wSM___ = zeros(n_w_max,n_S,n_M,'like',f_zero);
delta_x_gpu_wSM___ = zeros(n_w_max,n_S,n_M,'like',f_zero);
delta_y_gpu_wSM___ = zeros(n_w_max,n_S,n_M,'like',f_zero);
gamma_z_gpu_wSM___ = zeros(n_w_max,n_S,n_M,'like',f_zero);
index_sub_gpu_wSM___ = zeros(n_w_max,n_S,n_M,'like',f_zero);
end;%if flag_optimize_over_gamma_z==0;
if flag_optimize_over_gamma_z==1;
Z_gpu_SM__ = zeros(n_S,n_M,'like',f_zero);
UX_CTF_R_S_l2_gpu_wSM___ = zeros(n_S,n_M,'like',f_zero);
X_gpu_SM__ = zeros(n_S,n_M,'like',f_zero);
delta_x_gpu_SM__ = zeros(n_S,n_M,'like',f_zero);
delta_y_gpu_SM__ = zeros(n_S,n_M,'like',f_zero);
gamma_z_gpu_SM__ = zeros(n_S,n_M,'like',f_zero);
index_sub_gpu_SM__ = zeros(n_S,n_M,'like',f_zero);
end;%if flag_optimize_over_gamma_z==1;

Z_dwSM____=[];
X_dwSM____=[];
if flag_dwSM;
n_dwSM = n_delta_v*n_w_max*n_S*n_M;
n_dwSM_GB = n_dwSM*n_byte_per_float64/1e9;
if (flag_verbose); tmp_str = 'X_dwSM____'; disp(sprintf(' %% memory: %s --> %0.6f GB',tmp_str,n_dwSM_GB)); end;
if (n_dwSM_GB> memory_limit_GB);
disp(sprintf(' %% Warning, n_dwSM_GB %0.2f in %s',n_dwSM_GB,str_thisfunction));
flag_dwSM = 0;
end;%if (n_dwSM_GB> memory_limit_GB);
if (n_dwSM_GB<=memory_limit_GB);
Z_dwSM____ = zeros(n_delta_v,n_w_max,n_S,n_M); %<-- not on gpu. ;
X_dwSM____ = zeros(n_delta_v,n_w_max,n_S,n_M); %<-- not on gpu. ;
flag_dwSM = 1;
end;%if (n_dwSM_GB<=memory_limit_GB);
end;%if flag_dwSM;

if (flag_verbose>0); 
tmp_str = 'UX_CTF_R_S_l2_gpu_wSM___'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
tmp_str = 'UX_T_M_l2_gpu_dM__'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
tmp_str = 'UX_M_l2_gpu_M_'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
if flag_optimize_over_gamma_z==0;
tmp_str = 'Z_gpu_wSM___'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
tmp_str = 'X_gpu_wSM___'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
tmp_str = 'delta_x_gpu_wSM___'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
tmp_str = 'delta_y_gpu_wSM___'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
tmp_str = 'gamma_z_gpu_wSM___'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
end;%if flag_optimize_over_gamma_z==0;
if flag_optimize_over_gamma_z==1;
tmp_str = 'Z_gpu_SM__'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
tmp_str = 'X_gpu_SM__'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
tmp_str = 'delta_x_gpu_SM__'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
tmp_str = 'delta_y_gpu_SM__'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
tmp_str = 'gamma_z_gpu_SM__'; disp(sprintf(' %% memory_gpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9));
end;%if flag_optimize_over_gamma_z==1;
if (flag_dwSM); tmp_str = 'Z_dwSM____'; disp(sprintf(' %% memory_cpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9)); end;
if (flag_dwSM); tmp_str = 'X_dwSM____'; disp(sprintf(' %% memory_cpu: %s --> %0.6f GB',tmp_str,whos(tmp_str).bytes/1e9)); end;
end;%if (flag_verbose>0); 

%%%%;
% Prepare UX_M_k_q_wnM__. ;
%%%%;
tmp_t = tic();
M_k_q_wkM__ = interp_p_to_q(n_k_p_r,n_w_,n_w_sum,M_k_p_wkM__);
%[~,UX_M_k_p_wnM__] = tfpmhh_pm_wUX_0([],n_k_p_r,pm_n_k_p_r,pm_wUX_kn__,n_w_max,n_M,M_k_p_wkM__);
%UX_M_k_q_wnM__ = interp_p_to_q(pm_n_k_p_r,pm_n_w_,pm_n_w_sum,UX_M_k_p_wnM__);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% UX_M_k_q_wnM__: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: UX_M_k_q_wnM__',str_thisfunction),tmp_t);
%UX_M_k_q_gpu_wnM__ = gpuArray( (UX_M_k_q_wnM__) );
%%%%;
% Prepare CTF_M_k_q_wnM__. ;
%%%%;
tmp_t = tic();
CTF_M_k_p_wkM__ = CTF_k_p_wkM__ .* M_k_p_wkM__;
CTF_M_k_q_wkM__ = interp_p_to_q(n_k_p_r,n_w_,n_w_sum,CTF_M_k_p_wkM__);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% CTF_M_k_q_wkM__: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: CTF_M_k_q_wkM__',str_thisfunction),tmp_t);
%%%%;
% Prepare UX_CC_k_q_wnM__. ;
%%%%;
tmp_t = tic();
CTF_k_q_wkM__ = interp_p_to_q(n_k_p_r,n_w_,n_w_sum,CTF_k_p_wkM__);
CC_k_p_wkM__ = conj(CTF_k_p_wkM__).*CTF_k_p_wkM__;
CC_k_q_wkM__ = interp_p_to_q(n_k_p_r,n_w_,n_w_sum,CC_k_p_wkM__);
[~,UX_CC_k_p_wnM__] = tfpmhh_pm_wUX_0([],n_k_p_r,pm_n_k_p_r,pm_wUX_kn__,n_w_max,n_M,CC_k_p_wkM__);
UX_CC_k_q_wnM__ = interp_p_to_q(pm_n_k_p_r,pm_n_w_,pm_n_w_sum,UX_CC_k_p_wnM__);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% UX_CC_k_q_wnM__: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: UX_CC_k_q_wnM__',str_thisfunction),tmp_t);
UX_CC_k_q_gpu_wnM__ = gpuArray( (UX_CC_k_q_wnM__) );
%%%%;

%%%%;
% Prepare UX_S_k_q_wnS__. ;
%%%%;
tmp_t = tic();
S_k_q_wkS__ = interp_p_to_q(n_k_p_r,n_w_,n_w_sum,S_k_p_wkS__);
[~,UX_S_k_p_wnS__] = tfpmhh_pm_wUX_0([],n_k_p_r,pm_n_k_p_r,pm_wUX_kn__,n_w_max,n_S,S_k_p_wkS__);
UX_S_k_q_wnS__ = interp_p_to_q(pm_n_k_p_r,pm_n_w_,pm_n_w_sum,UX_S_k_p_wnS__);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% UX_S_k_q_wnS__: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: UX_S_k_q_wnS__',str_thisfunction),tmp_t);
UX_S_k_q_gpu_wnS__ = gpuArray( (UX_S_k_q_wnS__) );
%%%%;
% Prepare UX_SS_k_q_wnS__. ;
%%%%;
tmp_t = tic();
SS_k_p_wkS__ = conj(S_k_p_wkS__).*S_k_p_wkS__;
SS_k_q_wkS__ = interp_p_to_q(n_k_p_r,n_w_,n_w_sum,SS_k_p_wkS__);
[~,UX_SS_k_p_wnS__] = tfpmhh_pm_wUX_0([],n_k_p_r,pm_n_k_p_r,pm_wUX_kn__,n_w_max,n_S,SS_k_p_wkS__);
UX_SS_k_q_wnS__ = interp_p_to_q(pm_n_k_p_r,pm_n_w_,pm_n_w_sum,UX_SS_k_p_wnS__);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% UX_SS_k_q_wnS__: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: UX_SS_k_q_wnS__',str_thisfunction),tmp_t);
UX_SS_k_q_gpu_wnS__ = gpuArray( (UX_SS_k_q_wnS__) );

n_M_per_Mbatch = max(1,n_M_per_Mbatch);
n_S_per_Sbatch = max(1,n_S_per_Sbatch);
n_dwSM = n_delta_v*n_w_max*n_S_per_Sbatch*n_M_per_Mbatch;
n_dwSM_GB = n_dwSM*n_byte_per_float64/1e9;
if (n_dwSM_GB> memory_limit_GB); disp(sprintf(' %% Warning, n_dwSM_GB %0.2f > %0.2f in %s',n_dwSM_GB,memory_limit_GB,str_thisfunction)); return; end;
n_Mbatch = ceil(n_M/max(1,n_M_per_Mbatch));
if (flag_verbose>1); disp(sprintf(' %% n_Mbatch %d',n_Mbatch)); end;
n_Sbatch = ceil(n_S/max(1,n_S_per_Sbatch));
if (flag_verbose>1); disp(sprintf(' %% n_Sbatch %d',n_Sbatch)); end;

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
for nMbatch=0:n_Mbatch-1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
index_nM_in_Mbatch_ = nMbatch*n_M_per_Mbatch + (0:n_M_per_Mbatch-1);
index_nM_in_Mbatch_ = index_nM_in_Mbatch_(1+efind(index_nM_in_Mbatch_<n_M)); n_M_sub = numel(index_nM_in_Mbatch_);
if (flag_verbose>1); disp(sprintf(' %% nMbatch %d/%d index_nM_in_Mbatch_ %d-->%d',nMbatch,n_Mbatch,index_nM_in_Mbatch_(1+0),index_nM_in_Mbatch_(1+n_M_sub-1))); end;
if (flag_verbose>0 & mod(nMbatch,1)==0); disp(sprintf(' %% nMbatch %d/%d index_nM_in_Mbatch_ %d-->%d',nMbatch,n_Mbatch,index_nM_in_Mbatch_(1+0),index_nM_in_Mbatch_(1+n_M_sub-1))); end;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
if (n_M_sub>0);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
tmp_t = tic();
%M_sub_k_p_gpu_wkM__ = gpuArray( M_k_p_wkM__(:,1+index_nM_in_Mbatch_) );
M_sub_k_q_gpu_wkM__ = gpuArray( M_k_q_wkM__(:,1+index_nM_in_Mbatch_) );
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% M_sub_k_q_gpu_wkM__: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: M_sub_k_q_gpu_wkM__',str_thisfunction),tmp_t);
UX_M_sub_l2_gpu_M_ = zeros(n_M_sub,1,'like',f_zero);
UX_T_M_sub_l2_gpu_dM__ = zeros(n_delta_v,n_M_sub,'like',f_zero);
%tmp_t = tic();
%CTF_sub_k_p_gpu_wkM__ = gpuArray( CTF_k_p_wkM__(:,1+index_nM_in_Mbatch_) );
%CTF_sub_k_q_gpu_wkM__ = gpuArray( CTF_k_q_wkM__(:,1+index_nM_in_Mbatch_) );
%tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% CTF_sub_k_q_gpu_wkM__: %0.6fs',tmp_t)); end;
%parameter = parameter_timing_update(parameter,sprintf('%s: CTF_sub_k_q_gpu_wkM__',str_thisfunction),tmp_t);
tmp_t = tic();
%CTF_M_sub_k_p_gpu_wkM__ = gpuArray( CTF_M_k_p_wkM__(:,1+index_nM_in_Mbatch_) );
CTF_M_sub_k_q_gpu_wkM__ = gpuArray( CTF_M_k_q_wkM__(:,1+index_nM_in_Mbatch_) );
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% CTF_M_sub_k_q_gpu_wkM__: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: CTF_M_sub_k_q_gpu_wkM__',str_thisfunction),tmp_t);
tmp_t = tic();
%CC_sub_k_p_wkM__ = CC_k_p_wkM__(:,1+index_nM_in_Mbatch_);
%CC_sub_k_q_wkM__ = CC_k_q_wkM__(:,1+index_nM_in_Mbatch_);
%UX_CC_sub_k_p_gpu_wnM__ = gpuArray( UX_CC_k_p_wnM__(:,1+index_nM_in_Mbatch_) );
UX_CC_sub_k_q_gpu_wnM__ = gpuArray( UX_CC_k_q_wnM__(:,1+index_nM_in_Mbatch_) );
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% UX_CC_sub_k_q_gpu_wnM__: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: UX_CC_sub_k_q_gpu_wnM__',str_thisfunction),tmp_t);
%%%%;
% Prepare quasi-images. ;
%%%%;
tmp_t = tic();
svd_V_UX_CTF_M_sub_gpu_lwnM____ = tpmh_VUXM_gpu_lwnM____4(FTK,n_k_p_r,n_w_,n_M_sub,CTF_M_sub_k_q_gpu_wkM__,pm_n_UX_rank,pm_UX_gpu_kn__,pm_X_weight_gpu_r_);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% svd_V_UX_CTF_M_sub_gpu_lwnM____: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: svd_V_UX_CTF_M_sub_gpu_lwnM____',str_thisfunction),tmp_t);
tmp_t = tic();
svd_V_UX_M_sub_gpu_lwnM____ = tpmh_VUXM_gpu_lwnM____4(FTK,n_k_p_r,n_w_,n_M_sub,M_sub_k_q_gpu_wkM__,pm_n_UX_rank,pm_UX_gpu_kn__,pm_X_weight_gpu_r_);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% svd_V_UX_M_sub_gpu_lwnM____: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: svd_V_UX_M_sub_gpu_lwnM____',str_thisfunction),tmp_t);
tmp_t = tic();
svd_V_UX_CTF_M_sub_gpu_nMwl____ = permute(svd_V_UX_CTF_M_sub_gpu_lwnM____,1+[2,3,1,0]);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% svd_V_UX_CTF_M_sub_gpu_nMwl____: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: svd_V_UX_CTF_M_sub_gpu_nMwl____',str_thisfunction),tmp_t);
%%%%;
% Now calculate norms of the translated images. ;
%%%%;
tmp_t = tic();
UX_T_M_sub_l2_gpu_dM__ = tfpmh_UX_T_M_l2_gpu_dM__1(n_delta_v,n_svd_l,svd_U_d_expiw_s_gpu__,n_w_max,n_M_sub,pm_n_UX_rank,svd_V_UX_M_sub_gpu_lwnM____);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% tfpmh_UX_T_M_sub_l2_gpu_dM__1: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: tfpmh_UX_T_M_sub_l2_gpu_dM__1',str_thisfunction),tmp_t);
UX_M_sub_l2_gpu_M_ = reshape(UX_T_M_sub_l2_gpu_dM__(1+tmp_index_d0,:),[n_M_sub,1]);
UX_M_l2_gpu_M_(1+index_nM_in_Mbatch_) = UX_M_sub_l2_gpu_M_; %<-- store results. ;
UX_T_M_l2_gpu_dM__(:,1+index_nM_in_Mbatch_) = UX_T_M_sub_l2_gpu_dM__; %<-- store results. ;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
for nSbatch=0:n_Sbatch-1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
index_nS_in_Sbatch_ = nSbatch*n_S_per_Sbatch + (0:n_S_per_Sbatch-1);
index_nS_in_Sbatch_ = index_nS_in_Sbatch_(1+efind(index_nS_in_Sbatch_<n_S)); n_S_sub = numel(index_nS_in_Sbatch_);
if (flag_verbose>2); disp(sprintf(' %% nSbatch %d/%d index_nS_in_Sbatch_ %d-->%d',nSbatch,n_Sbatch,index_nS_in_Sbatch_(1+0),index_nS_in_Sbatch_(1+n_S_sub-1))); end;
if (flag_verbose>1 & mod(nSbatch,32)==0); disp(sprintf(' %% nSbatch %d/%d index_nS_in_Sbatch_ %d-->%d',nSbatch,n_Sbatch,index_nS_in_Sbatch_(1+0),index_nS_in_Sbatch_(1+n_S_sub-1))); end;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
if (n_S_sub>0);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
%S_sub_k_p_wkS__ = S_k_p_wkS__(:,1+index_nS_in_Sbatch_);
%S_sub_k_q_wkS__ = S_k_q_wkS__(:,1+index_nS_in_Sbatch_);
%SS_sub_k_p_wkS__ = SS_k_p_wkS__(:,1+index_nS_in_Sbatch_);
%SS_sub_k_q_wkS__ = SS_k_q_wkS__(:,1+index_nS_in_Sbatch_);
%%%%;
% Prepare template norms. ;
%%%%;
if flag_CTF_anisotropic==0;
tmp_t = tic();
%UX_SS_sub_k_p_gpu_wnS__ = gpuArray( UX_SS_k_p_wnS__(:,1+index_nS_in_Sbatch_) );
UX_SS_sub_k_q_gpu_wnS__ = gpuArray( UX_SS_k_q_wnS__(:,1+index_nS_in_Sbatch_) );
UX_CTF_sub_R_S_sub_l2_gpu_SM__ = squeeze(sum(bsxfun(@times,reshape(UX_CC_sub_k_q_gpu_wnM__,[pm_n_w_sum,1,n_M_sub]),reshape(conj(UX_SS_sub_k_q_gpu_wnS__),[pm_n_w_sum,n_S_sub,1])),1+0)) / max(1,pm_n_w_max) ;
UX_CTF_sub_R_S_sub_l2_gpu_SM__ = real(UX_CTF_sub_R_S_sub_l2_gpu_SM__);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% UX_CTF_sub_R_S_sub_l2_gpu_SM__: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: UX_CTF_sub_R_S_sub_l2_gpu_SM__',str_thisfunction),tmp_t);
end;%if flag_CTF_anisotropic==0;
if flag_CTF_anisotropic==1;
tmp_t = tic();
UX_CTF_sub_R_S_sub_l2_gpu_wSM___ = zeros(n_w_max,n_S_sub,n_M_sub,'like',f_zero);
UX_SS_sub_k_q_gpu_wnS__ = UX_SS_k_q_wnS__(:,1+index_nS_in_Sbatch_);
UX_CTF_sub_R_S_sub_l2_gpu_wSM___ = ifft(squeeze(sum(reshape(bsxfun(@times,reshape(UX_CC_sub_k_q_gpu_wnM__,[pm_n_w_sum,1,n_M_sub]),reshape(conj(UX_SS_sub_k_q_gpu_wnS__),[pm_n_w_sum,n_S_sub,1])),[pm_n_w_max,pm_n_k_p_r,n_S_sub,n_M_sub]),1+1)));
UX_CTF_sub_R_S_sub_l2_gpu_wSM___ = real(UX_CTF_sub_R_S_sub_l2_gpu_wSM___);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% UX_CTF_sub_R_S_sub_l2_gpu_wSM___: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: UX_CTF_sub_R_S_sub_l2_gpu_wSM___',str_thisfunction),tmp_t);
end;%if flag_CTF_anisotropic==1;
%%%%;
% Prepare UX_S_k_q_wnS__. ;
%%%%;
tmp_t = tic();
UX_S_sub_k_q_wnS__ = UX_S_k_q_wnS__(:,1+index_nS_in_Sbatch_);
UX_S_sub_k_q_nSw___ = permute(reshape(UX_S_sub_k_q_wnS__,[n_w_max,pm_n_UX_rank,n_S_sub]),1+[1,2,0]);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% UX_S_sub_k_q_nSw__: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: UX_S_sub_k_q_nSw__',str_thisfunction),tmp_t);
%%%%;
% Calculate innerproduct Z_sub_dwSM____. ;
%%%%;
tmp_t = tic();
svd_S_sub_V_UX_CTF_M_sub_gpu_SMwl____ = pagemtimes(UX_S_sub_k_q_nSw___,'ctranspose',svd_V_UX_CTF_M_sub_gpu_nMwl____,'none');
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% svd_S_sub_V_UX_CTF_M_sub_gpu_SMwl____: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: svd_S_sub_V_UX_CTF_M_sub_gpu_SMwl____',str_thisfunction),tmp_t);
tmp_t = tic();
%svd_S_sub_V_UX_CTF_M_sub_gpu_lwSM____ = ifft(permute(svd_S_sub_V_UX_CTF_M_sub_gpu_SMwl____,1+[3,2,0,1]),[],1+1)*n_w_max;
svd_S_sub_V_UX_CTF_M_sub_gpu_lwSM____ = permute(ifft(permute(svd_S_sub_V_UX_CTF_M_sub_gpu_SMwl____,1+[2,3,0,1]),[],1+0)*n_w_max,1+[1,0,2,3]);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% svd_S_sub_V_UX_CTF_M_sub_gpu_lwSM____: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: svd_S_sub_V_UX_CTF_M_sub_gpu_lwSM____',str_thisfunction),tmp_t);
tmp_t = tic();
svd_UES_S_sub_V_UX_CTF_M_sub_gpu_dwSM____ = reshape(pagemtimes(svd_U_d_expiw_s_gpu__,svd_S_sub_V_UX_CTF_M_sub_gpu_lwSM____),[n_delta_v,n_w_max,n_S_sub,n_M_sub]);
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% svd_UES_S_sub_V_UX_CTF_M_sub_gpu_dwSM____: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: svd_UES_S_sub_V_UX_CTF_M_sub_gpu_dwSM____',str_thisfunction),tmp_t);
Z_sub_gpu_dwSM____  = real(svd_UES_S_sub_V_UX_CTF_M_sub_gpu_dwSM____);
%%%%;
% Calculate correlation. ;
%%%%;
tmp_t = tic();
if flag_CTF_anisotropic==1;
%UX_CTF_sub_R_S_sub_l2_gpu_wSM___ = UX_CTF_R_S_l2_gpu_wSM___(:,1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_);
X_sub_gpu_dwSM____ = bsxfun(@rdivide,bsxfun(@rdivide,Z_sub_gpu_dwSM____,max(1e-12,reshape(sqrt(UX_CTF_sub_R_S_sub_l2_gpu_wSM___),[1,n_w_max,n_S_sub,n_M_sub]))),max(1e-12,reshape(sqrt(UX_T_M_sub_l2_gpu_dM__),[n_delta_v,1,1,n_M_sub])));
end;%if flag_CTF_anisotropic==1;
if flag_CTF_anisotropic==0;
%UX_CTF_sub_R_S_sub_l2_gpu_SM__ = UX_CTF_R_S_l2_gpu_SM__(1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_);
X_sub_gpu_dwSM____ = bsxfun(@rdivide,bsxfun(@rdivide,Z_sub_gpu_dwSM____,max(1e-12,reshape(sqrt(UX_CTF_sub_R_S_sub_l2_gpu_SM__),[1,1,n_S_sub,n_M_sub]))),max(1e-12,reshape(sqrt(UX_T_M_sub_l2_gpu_dM__),[n_delta_v,1,1,n_M_sub])));
end;%if flag_CTF_anisotropic==0;
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% X_sub_gpu_dwSM____: %0.6fs',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: X_sub_gpu_dwSM____',str_thisfunction),tmp_t);
%%%%;
% Store results. ;
%%%%;
if flag_dwSM;
Z_dwSM____(:,:,1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = gather(Z_sub_gpu_dwSM____);
X_dwSM____(:,:,1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = gather(X_sub_gpu_dwSM____);
end;%if flag_dwSM;
%%%%%%%%;
if flag_optimize_over_gamma_z==0;
tmp_t = tic();
n_wSM = n_w_max*n_S_sub*n_M_sub;
[tmp_X_gpu_wSM_,tmp_ij_delta_gpu_wSM_] = max(reshape(X_sub_gpu_dwSM____,[n_delta_v,n_wSM]),[],1+0); %<-- maximize correlation. ;
tmp_index_delta_gpu_wSM_ = tmp_ij_delta_gpu_wSM_-1;
assert(min(tmp_index_delta_gpu_wSM_,[],'all')>=0); assert(max(tmp_index_delta_gpu_wSM_,[],'all')<=n_delta_v-1);
tmp_X_gpu_wSM___ = reshape(tmp_X_gpu_wSM_,[n_w_max,n_S_sub,n_M_sub]);
tmp_index_all_gpu_wSM_ = tmp_index_delta_gpu_wSM_ + reshape(gpuArray( [0:n_wSM-1] ),size(tmp_index_delta_gpu_wSM_))*n_delta_v;
assert(min(tmp_index_all_gpu_wSM_,[],'all')>=0); assert(max(tmp_index_all_gpu_wSM_,[],'all')<=n_delta_v*n_wSM-1);
tmp_Z_gpu_wSM___ = reshape(Z_sub_gpu_dwSM____(1+tmp_index_all_gpu_wSM_),[n_w_max,n_S_sub,n_M_sub]);
tmp_index_delta_gpu_wSM___ = reshape(tmp_index_delta_gpu_wSM_,[n_w_max,n_S_sub,n_M_sub]);
tmp_delta_x_gpu_wSM___ = delta_gpu_x_(1+tmp_index_delta_gpu_wSM___);
tmp_delta_y_gpu_wSM___ = delta_gpu_y_(1+tmp_index_delta_gpu_wSM___);
tmp_gamma_z_gpu_wSM___ = 2*pi*(gpuArray( [0:n_w_max-1] ))/max(1,n_w_max);
Z_gpu_wSM___(:,1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = tmp_Z_gpu_wSM___;
X_gpu_wSM___(:,1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = tmp_X_gpu_wSM___;
delta_x_gpu_wSM___(:,1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(tmp_delta_x_gpu_wSM___,[n_w_max,n_S_sub,n_M_sub]);
delta_y_gpu_wSM___(:,1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(tmp_delta_y_gpu_wSM___,[n_w_max,n_S_sub,n_M_sub]);
gamma_z_gpu_wSM___(:,1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = repmat(tmp_gamma_z_gpu_wSM___(:),[1,n_S_sub,n_M_sub]);
index_sub_gpu_wSM___(:,1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(tmp_index_delta_gpu_wSM_,[n_w_max,n_S_sub,n_M_sub]);
if flag_CTF_anisotropic==0;
UX_CTF_R_S_l2_gpu_SM__(1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(UX_CTF_sub_R_S_sub_l2_gpu_SM__,[n_S_sub,n_M_sub]);
end;%if flag_CTF_anisotropic==0;
if flag_CTF_anisotropic==1;
UX_CTF_R_S_l2_gpu_wSM___(:,1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(UX_CTF_sub_R_S_sub_l2_gpu_wSM___,[n_w_max,n_S_sub,n_M_sub]);
end;%if flag_CTF_anisotropic==1;
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% X_gpu_wSM___: %0.6f',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: X_gpu_wSM___',str_thisfunction),tmp_t);
end;%if flag_optimize_over_gamma_z==0;
%%%%%%%%;
if flag_optimize_over_gamma_z==1;
tmp_t = tic();
n_dw = n_delta_v*n_w_max; n_SM = n_S_sub*n_M_sub;
[tmp_X_gpu_SM_,tmp_ij_dw_gpu_SM_] = max(reshape(X_sub_gpu_dwSM____,[n_dw,n_SM]),[],1+0); %<-- maximize correlation. ;
tmp_index_dw_gpu_SM_ = tmp_ij_dw_gpu_SM_-1;
assert(min(tmp_index_dw_gpu_SM_,[],'all')>=0); assert(max(tmp_index_dw_gpu_SM_,[],'all')<=n_dw-1);
tmp_X_gpu_SM__ = reshape(tmp_X_gpu_SM_,[n_S_sub,n_M_sub]);
tmp_index_all_gpu_SM_ = tmp_index_dw_gpu_SM_ + reshape(gpuArray( [0:n_SM-1] ),size(tmp_index_dw_gpu_SM_))*n_dw;
assert(min(tmp_index_all_gpu_SM_,[],'all')>=0); assert(max(tmp_index_all_gpu_SM_,[],'all')<=n_dw*n_SM-1);
tmp_Z_gpu_SM__ = reshape(Z_sub_gpu_dwSM____(1+tmp_index_all_gpu_SM_),[n_S_sub,n_M_sub]);
tmp_index_dw_gpu_SM__ = reshape(tmp_index_dw_gpu_SM_,[n_S_sub,n_M_sub]);
tmp_index_delta_gpu_SM__ = mod(tmp_index_dw_gpu_SM__,n_delta_v);
tmp_index_gamma_gpu_SM__ = (tmp_index_dw_gpu_SM__ - tmp_index_delta_gpu_SM__)/max(1,n_delta_v);
assert(min(tmp_index_delta_gpu_SM__,[],'all')>=0); assert(max(tmp_index_delta_gpu_SM__,[],'all')<=n_delta_v-1);
assert(min(tmp_index_gamma_gpu_SM__,[],'all')>=0); assert(max(tmp_index_gamma_gpu_SM__,[],'all')<=n_w_max-1);
tmp_index_delta_gpu_SM__ = reshape(tmp_index_delta_gpu_SM__,[n_S_sub,n_M_sub]);
tmp_index_gamma_gpu_SM__ = reshape(tmp_index_gamma_gpu_SM__,[n_S_sub,n_M_sub]);
tmp_delta_x_gpu_SM__ = delta_gpu_x_(1+tmp_index_delta_gpu_SM__);
tmp_delta_y_gpu_SM__ = delta_gpu_y_(1+tmp_index_delta_gpu_SM__);
tmp_gamma_z_gpu_SM__ = 2*pi*(tmp_index_gamma_gpu_SM__)/max(1,n_w_max);
Z_gpu_SM__(1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = tmp_Z_gpu_SM__;
X_gpu_SM__(1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = tmp_X_gpu_SM__;
delta_x_gpu_SM__(1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(tmp_delta_x_gpu_SM__,[n_S_sub,n_M_sub]);
delta_y_gpu_SM__(1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(tmp_delta_y_gpu_SM__,[n_S_sub,n_M_sub]);
gamma_z_gpu_SM__(1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(tmp_gamma_z_gpu_SM__,[n_S_sub,n_M_sub]);
index_sub_gpu_SM__(1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(tmp_index_dw_gpu_SM_,[n_S_sub,n_M_sub]);
if flag_CTF_anisotropic==0;
UX_CTF_R_S_l2_gpu_SM__(1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(UX_CTF_sub_R_S_sub_l2_gpu_SM__,[n_S_sub,n_M_sub]);
end;%if flag_CTF_anisotropic==0;
if flag_CTF_anisotropic==1;
tmp_index_all_gpu_SM_ = tmp_index_gamma_gpu_SM__ + reshape(gpuArray( [0:n_SM-1] ),size(tmp_index_gamma_gpu_SM__))*n_w_max;
tmp_UX_CTF_sub_R_S_sub_l2_gpu_SM__ = reshape(UX_CTF_sub_R_S_sub_l2_gpu_wSM___(1+tmp_index_all_gpu_SM_),[n_S_sub,n_M_sub]);
UX_CTF_R_S_l2_gpu_SM__(1+index_nS_in_Sbatch_,1+index_nM_in_Mbatch_) = reshape(tmp_UX_CTF_sub_R_S_sub_l2_gpu_SM__,[n_S_sub,n_M_sub]);
end;%if flag_CTF_anisotropic==1;
tmp_t = toc(tmp_t); if (flag_verbose>1); disp(sprintf(' %% X_gpu_SM__: %0.6f',tmp_t)); end;
parameter = parameter_timing_update(parameter,sprintf('%s: X_gpu_SM__',str_thisfunction),tmp_t);
end;%if flag_optimize_over_gamma_z==1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
end;%if (n_S_sub>0);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
end;%for nSbatch=0:n_Sbatch-1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
end;%if (n_M_sub>0);
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;
end;%for nMbatch=0:n_Mbatch-1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%;

if flag_optimize_over_gamma_z==1;
Z_gpu_wSM___ = Z_gpu_SM__;
X_gpu_wSM___ = X_gpu_SM__;
delta_x_gpu_wSM___ = delta_x_gpu_SM__;
delta_y_gpu_wSM___ = delta_y_gpu_SM__;
gamma_z_gpu_wSM___ = gamma_z_gpu_SM__;
index_sub_gpu_wSM___ = index_sub_gpu_SM__;
UX_CTF_R_S_l2_gpu_wSM___ = UX_CTF_R_S_l2_gpu_SM__;
end;%if flag_optimize_over_gamma_z==1;

if (flag_verbose>0); disp(sprintf(' %% [finished %s]',str_thisfunction)); end;

