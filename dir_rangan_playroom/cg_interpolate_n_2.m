function tensor_to_scatter__ = cg_interpolate_n_2(n_order,n_polar_a,n_azimu_b,n_scatter,polar_a_scatter_,azimu_b_scatter_);
% returns sparse matrix encoding the n_order interpolation operator between a tensor_grid ;
% using n_polar_a polar_a (uniformly from 0 to pi inclusive of endpoints) ;
% and n_azimu_b azimu_b (unformly from 0 to 2*pi with periodic boundary). ;
% We presume these points are associated with a (n_polar_a)-by-(n_azimu_b) matrix ;
% a_k_p__ with rows corresponding to polar_a_ and columns corresponding to azimu_b_. ;
% The n_scatter points to be interpolated have coordinates stored in ;
% polar_a_scatter_ and azimu_b_scatter_. ;
% We presume these points are associated with a n_scatter-element list a_k_all_. ;
% ;
% The (n_scatter)-by-(n_polar_a*n_azimu_b) tensor_to_scatter__ matrix stores the ;
% interpolation weights linking a_k_all_ to the unrolled a_k_p__(:). ;

if (nargin<6);
rng(1);
n_polar_a = 65; n_azimu_b = 128;
polar_a_ = transpose(linspace(0,1*pi,n_polar_a));
azimu_b_ = transpose(linspace(0,2*pi,n_azimu_b+1)); azimu_b_ = azimu_b_(1:end-1);
n_grid = n_polar_a*n_azimu_b;
[polar_a_grid_,azimu_b_grid_] = ndgrid(polar_a_,azimu_b_);
n_scat = 1024;
polar_a_scat_ = 1*pi*rand(n_scat,1);
azimu_b_scat_ = 2*pi*rand(n_scat,1);
l_max = 4;
[Ylm_grid__] = get_Ylm__(1+l_max,0:l_max,n_grid,azimu_b_grid_,polar_a_grid_);
[Ylm_scat__] = get_Ylm__(1+l_max,0:l_max,n_scat,azimu_b_scat_,polar_a_scat_);
for n_order=[3,5,7];
tensor_to_scatter__ = cg_interpolate_n_2(n_order,n_polar_a,n_azimu_b,n_scat,polar_a_scat_,azimu_b_scat_);
Ylm_pint__ = cell(1+l_max,1);
for l_val=0:l_max;
for m_val=-l_val:+l_val;
Ylm_pint__{1+l_val}(1+l_val+m_val,:) = tensor_to_scatter__*transpose(Ylm_grid__{1+l_val}(1+l_val+m_val,:));
end;%for m_val=-l_val:+l_val;
end;%for l_val=0:l_max;
disp(sprintf(' %% interpolation relative error: n_order %d ',n_order));
for l_val=0:l_max;
for m_val=-l_val:+l_val;
disp(sprintf(' %% l_val %d m_val %+d : %0.16f',l_val,m_val,fnorm(Ylm_scat__{1+l_val}(1+l_val+m_val,:) - Ylm_pint__{1+l_val}(1+l_val+m_val,:))/fnorm(Ylm_scat__{1+l_val}(1+l_val+m_val,:))));
end;%for m_val=-l_val:+l_val;
end;%for l_val=0:l_max;
end;%for n_order=[3,5,7];
%%%%%%%%;
n_order = 5; 
n_polar_a = 65; n_azimu_b = 128;
n_scat = 1024*16; polar_a_scat_ = 1*pi*rand(n_scat,1); azimu_b_scat_ = 2*pi*rand(n_scat,1);
tensor_to_scatter__ = cg_interpolate_n_2(n_order,n_polar_a,n_azimu_b,n_scat,polar_a_scat_,azimu_b_scat_);
scatter_to_tensor__ = transpose(tensor_to_scatter__);
tmp_a_k_p_grid_ = randn(n_polar_a*n_azimu_b,1) + i*randn(n_polar_a*n_azimu_b,1);
tmp_a_k_p_scat_ = randn(n_scat,1) + i*randn(n_scat,1);
n_iteration = 256;
tmp_t=tic;
for niteration=1:n_iteration; 
tmp_a_k_p_scat_out_ = tensor_to_scatter__*tmp_a_k_p_grid_;
end;%for niteration=1:n_iteration; 
tmp_t=toc(tmp_t); 
disp(sprintf(' %% n_order %d n_polar_a %d n_azimu_b %d n_scatter %d n_iteration %d tensor_to_scatter__ %0.2fs',n_order,n_polar_a,n_azimu_b,n_scat,n_iteration,tmp_t));
tmp_t=tic;
for niteration=1:n_iteration; 
tmp_a_k_p_grid_out_ = scatter_to_tensor__*tmp_a_k_p_scat_;
end;%for niteration=1:n_iteration; 
tmp_t=toc(tmp_t); 
disp(sprintf(' %% n_order %d n_polar_a %d n_azimu_b %d n_scatter %d n_iteration %d: scatter_to_tensor__ %0.2fs',n_order,n_polar_a,n_azimu_b,n_scat,n_iteration,tmp_t));
disp(sprintf(' %% returning')); return;
end;%if (nargin<6);

if (n_order>min(n_polar_a,n_azimu_b)); disp(sprintf(' %% Warning, n_order %d > n_polar_a %d n_azimu_b %d',n_order,n_polar_a,n_azimu_b)); end;
n_order = min(n_order,min(n_polar_a,n_azimu_b));

spacing_polar_a = pi/(n_polar_a-1);
spacing_azimu_b = 2*pi/n_azimu_b;
polar_a_scatter_rescale_ = max(0,min(n_polar_a-1,periodize(polar_a_scatter_,0,1*pi)/spacing_polar_a));
azimu_b_scatter_rescale_ = periodize(azimu_b_scatter_,0,2*pi)/spacing_azimu_b;
n_half_order = floor(n_order/2);
polar_a_scatter_floor_ = min(n_polar_a-n_order,max(0,floor(polar_a_scatter_rescale_)-n_half_order));
azimu_b_scatter_floor_ = floor(azimu_b_scatter_rescale_)-n_half_order; %<-- do not loop around boundary just yet. ;
polar_a_scatter_shift_ = polar_a_scatter_rescale_ - polar_a_scatter_floor_;
azimu_b_scatter_shift_ = azimu_b_scatter_rescale_ - azimu_b_scatter_floor_;
node_x_ = transpose(0:n_order-1);
weight_denominator_ = prod( repmat(node_x_,1,n_order) - repmat(transpose(node_x_),n_order,1) + eye(n_order,n_order) , 2 ) ;
weight_numerator_polar_a__ = zeros(n_order,n_scatter);
weight_numerator_azimu_b__ = zeros(n_order,n_scatter);
index_col_polar_a__ = zeros(n_order,n_scatter);
index_col_azimu_b__ = zeros(n_order,n_scatter);
index_row__ = repmat(0:n_scatter-1,n_order^2,1);
for nscatter=0:n_scatter-1;
%weight_numerator_polar_a__(:,1+nscatter) = prod( polar_a_scatter_shift_(1+nscatter) - repmat(node_x_,1,n_order) + sparse(1+transpose([0:n_order-1]),1+transpose([0:n_order-1]),1-(polar_a_scatter_shift_(1+nscatter)-node_x_),n_order,n_order) , 1 ) ;
weight_numerator_polar_a__(:,1+nscatter) = prod( polar_a_scatter_shift_(1+nscatter) - repmat(node_x_,1,n_order) + diag(1-(polar_a_scatter_shift_(1+nscatter)-node_x_)) , 1);
%weight_numerator_azimu_b__(:,1+nscatter) = prod( azimu_b_scatter_shift_(1+nscatter) - repmat(node_x_,1,n_order) + sparse(1+transpose([0:n_order-1]),1+transpose([0:n_order-1]),1-(azimu_b_scatter_shift_(1+nscatter)-node_x_),n_order,n_order) , 1 ) ;
weight_numerator_azimu_b__(:,1+nscatter) = prod( azimu_b_scatter_shift_(1+nscatter) - repmat(node_x_,1,n_order) + diag(1-(azimu_b_scatter_shift_(1+nscatter)-node_x_)) , 1 ) ;
end;%for nscatter=0:n_scatter-1;
index_col_polar_a__ = bsxfun(@plus,reshape(polar_a_scatter_floor_,[1,n_scatter]),transpose([0:n_order-1]));
index_col_azimu_b__ = bsxfun(@plus,reshape(azimu_b_scatter_floor_,[1,n_scatter]),transpose([0:n_order-1]));
tmp_index_ = efind(index_col_azimu_b__>=n_azimu_b); index_col_azimu_b__(1+tmp_index_) = index_col_azimu_b__(1+tmp_index_) - n_azimu_b;
tmp_index_ = efind(index_col_azimu_b__< 0        ); index_col_azimu_b__(1+tmp_index_) = index_col_azimu_b__(1+tmp_index_) + n_azimu_b;
weight_polar_a__ = diag(1./weight_denominator_)*weight_numerator_polar_a__;
weight_azimu_b__ = diag(1./weight_denominator_)*weight_numerator_azimu_b__;
weight__ = zeros(n_order^2,n_scatter);
index_col__ = zeros(n_order^2,n_scatter);
for nscatter=0:n_scatter-1;
weight__(:,1+nscatter) = reshape(weight_polar_a__(:,1+nscatter)*transpose(weight_azimu_b__(:,1+nscatter)),[n_order^2,1]);
index_col__(:,1+nscatter) = reshape(bsxfun(@plus,index_col_polar_a__(:,1+nscatter),transpose(index_col_azimu_b__(:,1+nscatter))*n_polar_a),[n_order^2,1]);
end;%for nscatter=0:n_scatter-1;
tensor_to_scatter__ = sparse(1+index_row__(:),1+index_col__(:),weight__(:),n_scatter,n_polar_a*n_azimu_b);


